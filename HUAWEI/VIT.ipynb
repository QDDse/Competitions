{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811e92ca-2233-4568-ba89-ec7cdefc904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................\n",
      "...param: traindir: ../train/labeled_data/\n",
      "...param: train_metadir: ../\n",
      "...param: train_metafile: train_label.csv\n",
      "...param: testdir: ../test\n",
      "...param: test_metadir: None\n",
      "...param: test_metafile: None\n",
      "...param: epochs: 10\n",
      "...param: num_workers: 4\n",
      "...param: batch_size: 64\n",
      "...param: lr: 0.1\n",
      "...param: weight_decay: 1e-05\n",
      "...param: num_classes: 2\n",
      "...param: step_size: 5\n",
      "...param: gamma: 0.9\n",
      "...param: ckpt_name: None\n",
      "...param: submission_name: submission.csv\n",
      "...param: model_name: None\n",
      "...param: kfold: 5\n",
      "...param: device: cuda\n",
      "...param: resultdir: ./result\n",
      "...........................................................................\n"
     ]
    }
   ],
   "source": [
    "## Kflod-5\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from args import build_opt\n",
    "# from loaders import build_loader, build_loader_new\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "opt = build_opt()\n",
    "\n",
    "from utils import create_logger\n",
    "import timm\n",
    "## logger\n",
    "logger = create_logger('../logging')\n",
    "##\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1257d3-6e5d-474e-91a2-414d4cb0c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重置opt\n",
    "opt.epochs = 5\n",
    "opt.lr = 1e-1\n",
    "opt.model_name = 'efficientnet_b6'\n",
    "opt.batch_size = 10\n",
    "opt.kfold = 5\n",
    "## random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d17bf8-f07a-4463-a236-c7b10e6f209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_00000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_00001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_00002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_00003.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_00004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image  label\n",
       "0  train_00000.png      1\n",
       "1  train_00001.png      0\n",
       "2  train_00002.png      0\n",
       "3  train_00003.png      0\n",
       "4  train_00004.png      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../train_new.csv', index_col=0)\n",
    "train_df.head()\n",
    "# train_df['label'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e13a4-1555-4151-bc83-7505567c5d2f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326fccfb-0843-4240-a63e-7b6face77795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqddse\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/autodl-tmp/HUWEI/baseline/wandb/run-20220904_233507-2ox4ymbx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering/runs/2ox4ymbx\" target=\"_blank\">efficientnet_b6_aug</a></strong> to <a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## wandb\n",
    "wandb.login()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='HUAWEI_lane_rendering', \n",
    "    entity='qddse',\n",
    "    name='efficientnet_b6_aug',\n",
    "    reinit=True,\n",
    "    config=opt,\n",
    "    group='EffiNetb6',\n",
    "    job_type='train_fold1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c57369-674d-41d1-af96-3fff733f56d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0fe9cc0-e004-46b2-8600-0c2c4560edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainer\n",
    "class Trainer:\n",
    "    def __init__(self, dataloaders, optimizer, model, loss_fn, scheduler=None, device='cuda:0', amp=False, config=None):\n",
    "        self.train_loader, self.val_loader = dataloaders\n",
    "        self.train_loss = loss_fn\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.amp = amp\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        self.model.cuda()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = data_cache[0].cuda()\n",
    "            label = data_cache[1].long().cuda()\n",
    "            ## compute loss\n",
    "            pred = self.model(img)\n",
    "            loss = self.train_loss(pred, label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        return running_loss / (len(self.train_loader))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self):\n",
    "        self.model.eval()\n",
    "        valid_pbar = tqdm(enumerate(self.val_loader), total=len(self.val_loader))\n",
    "        valid_preds, valid_targets = [], []\n",
    "        valid_acc = 0.\n",
    "        for idx, cache in valid_pbar:\n",
    "            img = cache[0].cuda()\n",
    "            target = cache[1].cuda()\n",
    "            pred = self.model(img)\n",
    "            valid_acc += (pred.argmax(1) == target).sum().item()\n",
    "            \n",
    "        return valid_acc / len(self.val_loader.dataset)\n",
    "            \n",
    "    def train_one_epoch_with_mixup(self):\n",
    "        '''\n",
    "        Train one epoch using mixup\n",
    "        '''\n",
    "        if self.amp:\n",
    "            scaler = GradScaler()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = self._convert_if_not_tensor(data_cache[0], dtype=torch.float32)\n",
    "            target = self._convert_if_not_tensor(data_cache[1], dtype=torch.float32)\n",
    "\n",
    "            bs = img.shape[0]\n",
    "            ## Support Amp with Mixup\n",
    "            if self.amp:\n",
    "                # Mixup\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(mix_img).squeeze()\n",
    "                        ## mixup loss\n",
    "                        loss_a = self.train_loss_fn(output, tar_a)\n",
    "                        loss_b = self.train_loss_fn(output, tar_b)\n",
    "                        loss = loss_a * lam + (1-lam) * loss_b\n",
    "                        \n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self. scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "                else:\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(img).squeeze()\n",
    "                        loss = self.train_loss_fn(output, target)\n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    \n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "            else:  # no amp\n",
    "                ## mixup allowed\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    output = self.model(mix_img).squeeze()\n",
    "                    \n",
    "                    ## loss\n",
    "                    loss_a = self.train_loss_fn(output, tar_a)\n",
    "                    loss_b = self.train_loss_fn(output, tar_b)\n",
    "                    loss = loss_a * lam + (1-lam) * loss_b\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    if (bnum + 1)% self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                else:\n",
    "                    output = self.model(img).squeeze()\n",
    "                    loss = self.train_loss_fn(output, target)\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "            train_pbar.set_description(desc=f'loss: {loss.item():.4f}')\n",
    "            running_loss /= len(self.train_loader)\n",
    "            \n",
    "            # Rescale the targets and output before chugging in a matrix\n",
    "            output = output.sigmoid().detach() * 100.0\n",
    "            target = target.detach() * 100.0\n",
    "            train_preds += [output.cpu().numpy()]\n",
    "            train_labels += [target.cpu().numpy()]\n",
    "        \n",
    "        all_train_preds = np.concatenate(train_preds)\n",
    "        all_train_labels = np.concatenate(train_labels)\n",
    "        \n",
    "        # Tidy\n",
    "        del output, target, train_preds, train_labels, loss, img, meta, all_train_preds, all_train_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return running_loss\n",
    "    \n",
    "    def fit(self, fold: int=None, epochs:int = 10, output_dir:str='./ckpts/826/04/', custom_name:str='model_best.pth', gain_train=None, is_wandb=True, patience=4):\n",
    "        \"\"\"\n",
    "        Low-effort alternative for doing the complete training and validation process\n",
    "        args:\n",
    "            gain_train: str ,ckpts的地址\n",
    "        \"\"\"\n",
    "        ## scheduler\n",
    "        self.optimizer\n",
    "        best_loss = int(1e7)\n",
    "        best_acc = 0.0\n",
    "        if gain_train:\n",
    "            ckpt = torch.load(gain_train)\n",
    "            model_ckpt = ckpt['model']\n",
    "            self.model.load_state_dict(model_ckpt)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"{'*'*20} Epoch: {epoch} / {epochs} {'*'*20}\")\n",
    "            \n",
    "            train_running_loss = self.train_one_epoch()\n",
    "            print(f\"Training loss: {train_running_loss:.4f}\")\n",
    "            valid_acc = self.valid_one_epoch()\n",
    "            print(f\"Validation Acc : {valid_acc:.4f}\")\n",
    "            \n",
    "            if train_running_loss < best_loss:\n",
    "                best_loss = train_running_loss\n",
    "                self.save_model(output_dir, custom_name, loss_final=best_loss)\n",
    "                self.save_model(output_dir + '/fold_'+str(fold) + '/', 'model_' + str(epoch) + '.pth', best_loss)\n",
    "\n",
    "                print(f\"Saved model with train_loss: {best_loss:.4f}\")\n",
    "                es = 0\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter: {} / {}\".format(es, patience))\n",
    "                if es > patience:\n",
    "                    print('Early Stop with train_loss: {}, val_acc:{}'.format(train_running_loss, valid_acc))\n",
    "                    break\n",
    "            if best_acc < valid_acc:\n",
    "                best_acc = valid_acc\n",
    "                self.save_model(output_dir + 'via_acc', custom_name)\n",
    "        \n",
    "            ## logger\n",
    "            if is_wandb:\n",
    "                run.log({'epoch:': epoch, 'Fold': fold, 'loss_train:': train_running_loss, 'val_acc': valid_acc})\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "                \n",
    "    def save_model(self, path, name, verbose=False, loss_final=None):\n",
    "        \"\"\"\n",
    "        Saves the model at the provided destination\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "        except:\n",
    "            print(\"Errors encountered while making the output directory\")\n",
    "        torch.save({\n",
    "            'model':self.model.state_dict(), \n",
    "            'loss': loss_final,\n",
    "            },\n",
    "            os.path.join(path, name)\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"Model Saved at: {os.path.join(path, name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed0080d-d733-47a6-8cfb-a76f5cb8ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>train_15505.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642</th>\n",
       "      <td>train_09642.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23208</th>\n",
       "      <td>train_23208.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>train_07917.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23946</th>\n",
       "      <td>train_23946.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>train_13744.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>train_06531.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16565</th>\n",
       "      <td>train_16565.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23404</th>\n",
       "      <td>train_23404.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>train_00250.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>train_20476.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>train_11160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>train_24423.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>train_08615.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>train_12740.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>train_08340.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>train_04168.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>train_14734.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>train_17279.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>train_24978.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image  label  label_01\n",
       "15505  train_15505.png      0         0\n",
       "9642   train_09642.png      0         0\n",
       "23208  train_23208.png      0         0\n",
       "7917   train_07917.png      0         0\n",
       "23946  train_23946.png      0         0\n",
       "13744  train_13744.png      0         0\n",
       "6531   train_06531.png      0         0\n",
       "16565  train_16565.png      0         0\n",
       "23404  train_23404.png      0         0\n",
       "250    train_00250.png      0         0\n",
       "20476  train_20476.png      0         0\n",
       "11160  train_11160.png      0         0\n",
       "24423  train_24423.png      0         0\n",
       "8615   train_08615.png      0         0\n",
       "12740  train_12740.png      0         0\n",
       "8340   train_08340.png      0         0\n",
       "4168   train_04168.png      0         0\n",
       "14734  train_14734.png      0         0\n",
       "17279  train_17279.png      6         1\n",
       "24978  train_24978.png      0         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Convert_01(label):\n",
    "    '''\n",
    "    args:\n",
    "        label:int\n",
    "    '''\n",
    "    if label == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "## 将label 转化为0-1\n",
    "train_df['label_01'] = train_df['label'].apply(lambda x: Convert_01(x))\n",
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa50341f-c658-4eb0-a82e-7c733f61603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new_Dataset\n",
    "class Rane_Dataset(data.Dataset):\n",
    "    '''\n",
    "    args:\n",
    "        imagedir: 存放image的地址\n",
    "        df: Dataframe, train_df or val_df\n",
    "        tranfrom: \n",
    "    '''\n",
    "    def __init__(self, imagedir, df, transform, require_label=True):\n",
    "        self.imagedir = imagedir\n",
    "        self.df = df\n",
    "        self.require_label = require_label\n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.df.iloc[idx]\n",
    "        ## img\n",
    "        # image = Image.open(os.path.join(self.imagedir, line['image']))\n",
    "        # image = image.convert('RGB')\n",
    "        img = cv2.imread(os.path.join(self.imagedir, line['image']))\n",
    "        img = img.astype(np.float32)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image = img)['image']  ## Notice!! \n",
    "        ## label\n",
    "        label = line['label_01']\n",
    "        # print(type(class_label))\n",
    "        # if class_label == 0:\n",
    "        #     label = 0\n",
    "        # else:\n",
    "        #     label = 1\n",
    "        if self.require_label:\n",
    "            # print(type(image))\n",
    "            return (img, label)\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "def build_loader_new(\n",
    "        imagedir,\n",
    "        batch_size,\n",
    "        num_workers,\n",
    "        metafile,\n",
    "        require_label=True,\n",
    "        transform = None,\n",
    "):\n",
    "    if transform == None:\n",
    "        trfs = [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "        trfs = transforms.Compose(trfs)\n",
    "    else:\n",
    "        trfs = transform\n",
    "        \n",
    "    dataset = Rane_Dataset(imagedir, metafile, trfs, require_label)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780dbab5-9b0e-4604-8661-2f1746b27e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist for this model. Using random initialization.\n"
     ]
    }
   ],
   "source": [
    "## train\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## modified model    \n",
    "from models import Effnet, Swin_trm\n",
    "\n",
    "# model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "model = Effnet(model_name=opt.model_name)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# transform = T.Compose([\n",
    "#                       T.Resize((224, 224)),\n",
    "#                       #T.HorizontalFlip(p=0.5),\n",
    "#                       T.RandomHorizontalFlip(0.5),\n",
    "#                       T.RandomVerticalFlip(0.5),\n",
    "#                       # A.VerticalFlip(p=0.5),\n",
    "#                       # T.Random,\n",
    "#                       # A.RandomContrast(p=0.5),\n",
    "#                       T.RandomGrayscale(0.5),\n",
    "#                       # A.RandomBrightness(p=0.5),\n",
    "#                       T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#                       T.ToTensor(),\n",
    "#                 ])\n",
    "transform = A.Compose([\n",
    "                      ## Swin-Resolution: (384,384) \n",
    "                      A.Resize(384, 384),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                      A.RandomContrast(p=0.5),\n",
    "                      A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "transform_val = A.Compose([\n",
    "                      A.Resize(384, 384),\n",
    "                      # A.HorizontalFlip(p=0.5),\n",
    "                      # A.VerticalFlip(p=0.5),\n",
    "                      # A.RandomContrast(p=0.5),\n",
    "                      # A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= 20, eta_min=1e-4)\n",
    "\n",
    "kf = KFold(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aef5d4-e074-45bb-83fe-a78788d13a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Fold: 0 / 5 ********************\n",
      "******************** Fold: 1 / 5 ********************\n",
      "23331 5833\n",
      "******************** Epoch: 0 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4a1e962910482aa1bbe67e97080b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.7740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb530b3235c429ea570e05cc627211c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.8843\n",
      "Model Saved at: ../ckpts/9_04//fold_1/model_0.pth\n",
      "Saved model with train_loss: 2.7740\n",
      "******************** Epoch: 1 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e3a21471ad49198b684f3a566cfb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537291cb836f44c98ed0ce1ddf730c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.1164\n",
      "Model Saved at: ../ckpts/9_04//fold_1/model_1.pth\n",
      "Saved model with train_loss: 0.7843\n",
      "******************** Epoch: 2 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a7850e82cb421d9d89767903730f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c014d3a34e484d728ac11c5d28a49942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.8848\n",
      "Model Saved at: ../ckpts/9_04//fold_1/model_2.pth\n",
      "Saved model with train_loss: 0.6811\n",
      "******************** Epoch: 3 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338822a3e6834db5832cbe2a859a9468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609c6a5adc347199907a72717d4c024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.8836\n",
      "Model Saved at: ../ckpts/9_04//fold_1/model_3.pth\n",
      "Saved model with train_loss: 0.4134\n",
      "******************** Epoch: 4 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad90a6122234abf8cd8e4e2ad9d5596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc811b069bb34d449f819fe2275712f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.4975\n",
      "Counter: 1 / 4\n",
      "******************** Fold: 2 / 5 ********************\n",
      "23331 5833\n",
      "******************** Epoch: 0 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf9b47b0ca74e8dafae7b770b81c836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dc8ac19cd041bfa557b7d86a1b3f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc : 0.8865\n",
      "Model Saved at: ../ckpts/9_04//fold_2/model_0.pth\n",
      "Saved model with train_loss: 0.7093\n",
      "******************** Epoch: 1 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b063eed62eb946179d9c543caa74770a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, split in enumerate(kf.split(train_df)):\n",
    "    print(f\"{'*'*20} Fold: {fold} / {opt.kfold} {'*'*20}\")\n",
    "    if fold == 0 :\n",
    "        continue\n",
    "    train_ = train_df.iloc[split[0]]\n",
    "    val_ = train_df.iloc[split[1]]\n",
    "    print(train_.shape[0], val_.shape[0])\n",
    "    \n",
    "    train_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=train_,\n",
    "        require_label=True,\n",
    "        transform = transform\n",
    "    )\n",
    "    val_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=val_,\n",
    "        require_label=True,\n",
    "        transform=transform_val\n",
    "    )\n",
    "    Train = Trainer((train_loader, val_loader), optimizer, model, loss_fn, scheduler=lr_scheduler)\n",
    "    Train.fit(fold=fold, epochs=opt.epochs, output_dir='../ckpts/9_04/', gain_train='../ckpts/9_04/model_best.pth')\n",
    "    del Train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37a3b1-d08c-4764-a194-65bccf017640",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('shutdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e67bb-311e-40f2-ada6-c03d3c1a6123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
