{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33be3e9-56b1-4b6d-8dd2-b3bc502b0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................\n",
      "...param: traindir: ../train/labeled_data/\n",
      "...param: train_metadir: ../\n",
      "...param: train_metafile: train_label.csv\n",
      "...param: testdir: ../test\n",
      "...param: test_metadir: None\n",
      "...param: test_metafile: None\n",
      "...param: epochs: 10\n",
      "...param: num_workers: 4\n",
      "...param: batch_size: 64\n",
      "...param: lr: 0.1\n",
      "...param: weight_decay: 1e-05\n",
      "...param: num_classes: 2\n",
      "...param: step_size: 5\n",
      "...param: gamma: 0.9\n",
      "...param: ckpt_name: None\n",
      "...param: submission_name: submission.csv\n",
      "...param: model_name: None\n",
      "...param: kfold: 5\n",
      "...param: device: cuda\n",
      "...param: resultdir: ./result\n",
      "...........................................................................\n"
     ]
    }
   ],
   "source": [
    "## Kflod-5\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from args import build_opt\n",
    "from loaders import build_loader, build_loader_new\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "opt = build_opt()\n",
    "\n",
    "from utils import create_logger\n",
    "import timm\n",
    "## logger\n",
    "logger = create_logger('../logging')\n",
    "##\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4465686-25f7-4634-a81f-d31a4b79895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重置opt\n",
    "opt.epochs = 5\n",
    "opt.lr = 1e-3\n",
    "opt.model_name = 'efficientnet_b6'\n",
    "opt.batch_size = 16\n",
    "opt.kfold = 5\n",
    "## random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba79efb-1cf1-4802-9b05-b6b652a76e74",
   "metadata": {},
   "source": [
    "## DEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604d04d7-08fa-4b5c-bdf4-1df5db11064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = timm.list_models('*efficient*')\n",
    "# model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "# model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495e07e3-cecb-4696-8b5d-3ccde61e0976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_00000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_00001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_00002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_00003.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_00004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image  label\n",
       "0  train_00000.png      1\n",
       "1  train_00001.png      0\n",
       "2  train_00002.png      0\n",
       "3  train_00003.png      0\n",
       "4  train_00004.png      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../train_new.csv', index_col=0)\n",
    "train_df.head()\n",
    "# train_df['label'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f9484e-4092-4f2f-bb82-54cfe2544f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25767\n",
       "6     1719\n",
       "2      533\n",
       "4      269\n",
       "7      255\n",
       "5      247\n",
       "3      223\n",
       "1      151\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts() # 8 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d0aba-0c98-4759-823e-c4bca3d09f9e",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44378487-57fb-4816-aa30-72f7ef5827d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqddse\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6547665b-3b1a-4328-a097-f77df843bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/autodl-tmp/HUWEI/baseline/wandb/run-20220830_175222-2gndaw1t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering/runs/2gndaw1t\" target=\"_blank\">Effi-b6-baseline_KFold4_with_aug</a></strong> to <a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='HUAWEI_lane_rendering', \n",
    "    entity='qddse',\n",
    "    name='Effi-b6-baseline_KFold4_with_aug',\n",
    "    reinit=True,\n",
    "    config=opt,\n",
    "    group='EffiNetb6',\n",
    "    job_type='train'\n",
    ")\n",
    "\n",
    "## update config\n",
    "# api = wandb.Api()\n",
    "# run = api.run('qddse/HUAWEI_lane_rendering/1us1v6o4')\n",
    "# run.config['model_name'] = opt.model_name\n",
    "# run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5fa017-c690-4d96-a561-43d6a2165b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAIN Train\n",
    "# ckpt_middle = torch.load('../ckpts/8_22/efficientnet_b6_39_bestmodel.pth')\n",
    "# model.load_state_dict(ckpt_middle['model'])\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1048e6-eaef-4068-be2f-0c9c3fddd7c4",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccfa8dd9-e689-4e9f-9c5e-923a79c14d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Trainer\n",
    "class Trainer:\n",
    "    def __init__(self, dataloaders, optimizer, model, loss_fn, scheduler=None, device='cuda:0', amp=False, config=None):\n",
    "        self.train_loader, self.val_loader = dataloaders\n",
    "        self.train_loss = loss_fn\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.amp = amp\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        self.model.cuda()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = data_cache[0].cuda()\n",
    "            label = data_cache[1].long().cuda()\n",
    "            ## compute loss\n",
    "            pred = self.model(img)\n",
    "            loss = self.train_loss(pred, label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        return running_loss / (len(self.train_loader))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self):\n",
    "        self.model.eval()\n",
    "        valid_pbar = tqdm(enumerate(self.val_loader), total=len(self.val_loader))\n",
    "        valid_preds, valid_targets = [], []\n",
    "        valid_acc = 0.\n",
    "        for idx, cache in valid_pbar:\n",
    "            img = cache[0].cuda()\n",
    "            target = cache[1].cuda()\n",
    "            pred = self.model(img)\n",
    "            valid_acc += (pred.argmax(1) == target).sum().item()\n",
    "            \n",
    "        return valid_acc / len(self.val_loader.dataset)\n",
    "            \n",
    "    def train_one_epoch_with_mixup(self):\n",
    "        '''\n",
    "        Train one epoch using mixup\n",
    "        '''\n",
    "        if self.amp:\n",
    "            scaler = GradScaler()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = self._convert_if_not_tensor(data_cache[0], dtype=torch.float32)\n",
    "            target = self._convert_if_not_tensor(data_cache[1], dtype=torch.float32)\n",
    "\n",
    "            bs = img.shape[0]\n",
    "            ## Support Amp with Mixup\n",
    "            if self.amp:\n",
    "                # Mixup\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(mix_img).squeeze()\n",
    "                        ## mixup loss\n",
    "                        loss_a = self.train_loss_fn(output, tar_a)\n",
    "                        loss_b = self.train_loss_fn(output, tar_b)\n",
    "                        loss = loss_a * lam + (1-lam) * loss_b\n",
    "                        \n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self. scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "                else:\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(img).squeeze()\n",
    "                        loss = self.train_loss_fn(output, target)\n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    \n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "            else:  # no amp\n",
    "                ## mixup allowed\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    output = self.model(mix_img).squeeze()\n",
    "                    \n",
    "                    ## loss\n",
    "                    loss_a = self.train_loss_fn(output, tar_a)\n",
    "                    loss_b = self.train_loss_fn(output, tar_b)\n",
    "                    loss = loss_a * lam + (1-lam) * loss_b\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    if (bnum + 1)% self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                else:\n",
    "                    output = self.model(img).squeeze()\n",
    "                    loss = self.train_loss_fn(output, target)\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "            train_pbar.set_description(desc=f'loss: {loss.item():.4f}')\n",
    "            running_loss /= len(self.train_loader)\n",
    "            \n",
    "            # Rescale the targets and output before chugging in a matrix\n",
    "            output = output.sigmoid().detach() * 100.0\n",
    "            target = target.detach() * 100.0\n",
    "            train_preds += [output.cpu().numpy()]\n",
    "            train_labels += [target.cpu().numpy()]\n",
    "        \n",
    "        all_train_preds = np.concatenate(train_preds)\n",
    "        all_train_labels = np.concatenate(train_labels)\n",
    "        \n",
    "        # Tidy\n",
    "        del output, target, train_preds, train_labels, loss, img, meta, all_train_preds, all_train_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return running_loss\n",
    "    \n",
    "    def fit(self, fold: int=None, epochs:int = 10, output_dir:str='./ckpts/826/04/', custom_name:str='model_best.pth', gain_train=None, is_wandb=True):\n",
    "        \"\"\"\n",
    "        Low-effort alternative for doing the complete training and validation process\n",
    "        args:\n",
    "            gain_train: str ,ckpts的地址\n",
    "        \"\"\"\n",
    "        ## scheduler\n",
    "        self.optimizer\n",
    "        best_loss = int(1e7)\n",
    "        best_acc = 0.0\n",
    "        if gain_train:\n",
    "            ckpt = torch.load(gain_train)\n",
    "            model_ckpt = ckpt['model']\n",
    "            self.model.load_state_dict(model_ckpt)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"{'*'*20} Epoch: {epoch} / {epochs} {'*'*20}\")\n",
    "            \n",
    "            train_running_loss = self.train_one_epoch()\n",
    "            print(f\"Training loss: {train_running_loss:.4f}\")\n",
    "            valid_acc = self.valid_one_epoch()\n",
    "            print(f\"Validation Acc : {valid_acc:.4f}\")\n",
    "            \n",
    "            if train_running_loss < best_loss:\n",
    "                best_loss = train_running_loss\n",
    "                self.save_model(output_dir, custom_name, loss_final=best_loss)\n",
    "                self.save_model(output_dir + '/fold_'+str(fold) + '/', 'model_' + str(epoch) + '.pth', best_loss)\n",
    "\n",
    "                print(f\"Saved model with train_loss: {best_loss:.4f}\")\n",
    "                es = 0\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter: {} / {}\".format(es, self.config['patience']))\n",
    "                if es > self.config['patience']:\n",
    "                    print('Early Stop with train_loss: {}, val_acc:{}'.format(train_running_loss, valid_acc))\n",
    "                    break\n",
    "            if best_acc < valid_acc:\n",
    "                best_acc = valid_acc\n",
    "                self.save_model(output_dir + 'via_acc', custom_name)\n",
    "        \n",
    "            ## logger\n",
    "            if is_wandb:\n",
    "                run.log({'epoch:': epoch, 'Fold': fold, 'loss_train:': train_running_loss, 'val_acc': valid_acc})\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "                \n",
    "    def save_model(self, path, name, verbose=False, loss_final=None):\n",
    "        \"\"\"\n",
    "        Saves the model at the provided destination\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "        except:\n",
    "            print(\"Errors encountered while making the output directory\")\n",
    "        torch.save({\n",
    "            'model':self.model.state_dict(), \n",
    "            'loss': loss_final,\n",
    "            },\n",
    "            os.path.join(path, name)\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"Model Saved at: {os.path.join(path, name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be7686d-02a7-4b82-9619-57b15c4f62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>train_15505.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642</th>\n",
       "      <td>train_09642.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23208</th>\n",
       "      <td>train_23208.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>train_07917.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23946</th>\n",
       "      <td>train_23946.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>train_13744.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>train_06531.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16565</th>\n",
       "      <td>train_16565.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23404</th>\n",
       "      <td>train_23404.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>train_00250.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>train_20476.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>train_11160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>train_24423.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>train_08615.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>train_12740.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>train_08340.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>train_04168.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>train_14734.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>train_17279.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>train_24978.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image  label  label_01\n",
       "15505  train_15505.png      0         0\n",
       "9642   train_09642.png      0         0\n",
       "23208  train_23208.png      0         0\n",
       "7917   train_07917.png      0         0\n",
       "23946  train_23946.png      0         0\n",
       "13744  train_13744.png      0         0\n",
       "6531   train_06531.png      0         0\n",
       "16565  train_16565.png      0         0\n",
       "23404  train_23404.png      0         0\n",
       "250    train_00250.png      0         0\n",
       "20476  train_20476.png      0         0\n",
       "11160  train_11160.png      0         0\n",
       "24423  train_24423.png      0         0\n",
       "8615   train_08615.png      0         0\n",
       "12740  train_12740.png      0         0\n",
       "8340   train_08340.png      0         0\n",
       "4168   train_04168.png      0         0\n",
       "14734  train_14734.png      0         0\n",
       "17279  train_17279.png      6         1\n",
       "24978  train_24978.png      0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Convert_01(label):\n",
    "    '''\n",
    "    args:\n",
    "        label:int\n",
    "    '''\n",
    "    if label == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "## 将label 转化为0-1\n",
    "train_df['label_01'] = train_df['label'].apply(lambda x: Convert_01(x))\n",
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f019ce-8124-40e9-a6a7-1f9dce83661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test Dataset\n",
    "# from loaders import Rane_Dataset\n",
    "# data_set = Rane_Dataset(imagedir='../train/labeled_data/', df=train_df, transform=None)\n",
    "\n",
    "# loader =build_loader_new(imagedir='../train/labeled_data/', batch_size=32, num_workers=4, metafile=train_df)\n",
    "\n",
    "# inp = next(iter(loader))\n",
    "# inp[0].shape, inp[1]\n",
    "\n",
    "# # inp = data_set[0][0].unsqueeze(0)\n",
    "\n",
    "# from models import Effnet\n",
    "\n",
    "# # model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "# model = Effnet(model_name=opt.model_name).cuda()\n",
    "\n",
    "# out = model(inp[0].cuda())\n",
    "\n",
    "# target = inp[1]\n",
    "# target = target.long()\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# loss = criterion(out, target.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ae8b8-57a5-492b-8e1e-5123f5055e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Fold: 0 / 5 ********************\n",
      "******************** Fold: 1 / 5 ********************\n",
      "******************** Fold: 2 / 5 ********************\n",
      "23331 5833\n",
      "******************** Epoch: 0 / 5 ********************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5925674674e4a94a24c9d89bb2dce9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## modified model    \n",
    "from models import Effnet\n",
    "\n",
    "# model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "model = Effnet(model_name=opt.model_name)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# transform = T.Compose([\n",
    "#                       T.Resize((224, 224)),\n",
    "#                       #T.HorizontalFlip(p=0.5),\n",
    "#                       T.RandomHorizontalFlip(0.5),\n",
    "#                       T.RandomVerticalFlip(0.5),\n",
    "#                       # A.VerticalFlip(p=0.5),\n",
    "#                       # T.Random,\n",
    "#                       # A.RandomContrast(p=0.5),\n",
    "#                       T.RandomGrayscale(0.5),\n",
    "#                       # A.RandomBrightness(p=0.5),\n",
    "#                       T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#                       T.ToTensor(),\n",
    "#                 ])\n",
    "transform = A.Compose([\n",
    "                      A.Resize(300, 300),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                      A.RandomContrast(p=0.5),\n",
    "                      A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "transform_val = A.Compose([\n",
    "                      A.Resize(300, 300),\n",
    "                      # A.HorizontalFlip(p=0.5),\n",
    "                      # A.VerticalFlip(p=0.5),\n",
    "                      # A.RandomContrast(p=0.5),\n",
    "                      # A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= 20, eta_min=1e-4)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "    \n",
    "# writer = SummaryWriter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fb3af-376e-4802-93fd-7626694050f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, split in enumerate(kf.split(train_df)):\n",
    "    print(f\"{'*'*20} Fold: {fold} / {opt.kfold} {'*'*20}\")\n",
    "    if fold == 0 or fold == 1:\n",
    "        continue\n",
    "    train_ = train_df.iloc[split[0]]\n",
    "    val_ = train_df.iloc[split[1]]\n",
    "    print(train_.shape[0], val_.shape[0])\n",
    "    \n",
    "    train_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=train_,\n",
    "        require_label=True,\n",
    "        transform = transform\n",
    "    )\n",
    "    val_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=val_,\n",
    "        require_label=True,\n",
    "        transform=transform_val\n",
    "    )\n",
    "    Train = Trainer((train_loader, val_loader), optimizer, model, loss_fn, scheduler=lr_scheduler)\n",
    "    Train.fit(fold=fold, epochs=opt.epochs, output_dir='../ckpts/8_29/', gain_train='../ckpts/8_29/fold_2/model_4.pth')\n",
    "    del Train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086c6e6-c2fd-44a2-8cca-67dc3f342c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('shutdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054fe5d-dd3d-4e93-938b-b1d6394d28b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Origin_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "577fd353-0d5f-46e9-a865-a54856eb9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...start training\n",
      "------ Epoch: 0 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a87f84133e4b1fb2bea97a08cb30e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   1/ 30, loss: 0.1357, average time: 0.95.\n",
      "------ Epoch: 1 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82529d78791545d2ae66505e84e1ff32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   2/ 30, loss: 0.1330, average time: 0.94.\n",
      "------ Epoch: 2 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b555729346e14d8dadbf0af359cb0151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   3/ 30, loss: 0.1301, average time: 0.87.\n",
      "------ Epoch: 3 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a4a8ddd7df46a892517b791f61cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   4/ 30, loss: 0.1260, average time: 0.87.\n",
      "------ Epoch: 4 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b080561fcf714b779d82b92f159263e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   5/ 30, loss: 0.1216, average time: 0.87.\n",
      "------ Epoch: 5 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bff212cb5e4f028638bf0a37150693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   6/ 30, loss: 0.1166, average time: 0.87.\n",
      "------ Epoch: 6 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd89c396a594bbeb7e19322df13949c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   7/ 30, loss: 0.1109, average time: 0.87.\n",
      "------ Epoch: 7 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4cdb3fe384399aafa78a18ba131ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   8/ 30, loss: 0.1055, average time: 0.86.\n",
      "------ Epoch: 8 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817cc05a298f4373b334e3ab37701e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:   9/ 30, loss: 0.0995, average time: 0.87.\n",
      "------ Epoch: 9 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eebe1a114a442aa88c9d538c0220d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...epoch:  10/ 30, loss: 0.0917, average time: 0.87.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:300] . unexpected pos 138565696 vs 138565592",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3872/182170416.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch_l\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_bestmodel.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:300] . unexpected pos 138565696 vs 138565592"
     ]
    }
   ],
   "source": [
    "print('...start training')\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    print('------ Epoch: {} ------'.format(epoch))\n",
    "    \n",
    "    start_t = time.time()\n",
    "    min_loss = 100\n",
    "    epoch_l = 0\n",
    "    epoch_t = 0\n",
    "    for batch_idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        image, label = batch\n",
    "        image, label = image.to(opt.device), label.to(opt.device)\n",
    "        output = model(image)\n",
    "\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_l = l.item()\n",
    "        epoch_l += batch_l\n",
    "        batch_t = time.time() - start_t\n",
    "        epoch_t += batch_t\n",
    "        start_t = time.time()\n",
    "    lr_scheduler.step()\n",
    "    epoch_t = epoch_t / len(train_loader)\n",
    "    epoch_l = epoch_l / len(train_loader)\n",
    "    print('...epoch: {:3d}/{:3d}, loss: {:.4f}, average time: {:.2f}.'.format(\n",
    "        epoch + 1, opt.epochs, epoch_l, epoch_t))\n",
    "    ## WandB logging\n",
    "    run.log({'epoch:': epoch, 'loss_train:': epoch_l})\n",
    "    run.log({'epoch:': epoch, 'time_train:': epoch_t})\n",
    "    ## save model\n",
    "    if epoch_l < min_loss:\n",
    "        save_name = opt.model_name + '_' + str(epoch+20) + '_bestmodel.pth'\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'lr': opt.lr,\n",
    "            'loss': epoch_l},\n",
    "            os.path.join('../ckpts/8_25', save_name)\n",
    "        )\n",
    "        min_lossoss = epoch_l\n",
    "        ## Early-stop\n",
    "        es = 0\n",
    "    else:\n",
    "        es += 1\n",
    "        print('Counter {}/{}'.format(es, 4))  # 设置patience为4\n",
    "        if es > 3:\n",
    "            print('Early_stop with best model‘s running_loss:{}'.format(epoch_l))\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00130452-0157-44a8-b913-66e4398d9441",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SAVE CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af019f-f873-48bd-a81b-444fa93ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'model': model.state_dict(),\n",
    "#     'lr': '0.1*10 + 1e-4*10',\n",
    "#     'epoch': '10+10',},\n",
    "#     '../ckpts/res50_epoch10+10'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e65765-e296-4004-bd33-86dac55945b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"shutdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f9bf3-6d38-4583-8cf3-88a42b07dc71",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1f9f9e-d7ca-4bba-99bf-dba4a07b9113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...start predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee140a82dc747b5be5723f4b9fed5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## test_loader\n",
    "test_loader = build_loader(\n",
    "    imagedir=opt.testdir,\n",
    "    batch_size=opt.batch_size,\n",
    "    num_workers=opt.num_workers,\n",
    "    metadir=opt.test_metadir,\n",
    "    metafile=opt.test_metafile,\n",
    "    require_label=False\n",
    ")\n",
    "\n",
    "## 加载模型\n",
    "model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "ckpt = torch.load('../ckpts/baseline_724.pth')['model']\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "print('...start predicting')\n",
    "\n",
    "model.eval()\n",
    "to_prob = nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    imagenames, probs = list(), list()\n",
    "    for batch_idx, batch in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        image, imagename = batch\n",
    "        image = image.to(opt.device)\n",
    "        pred = model(image)\n",
    "        prob = to_prob(pred)\n",
    "        prob = list(prob.data.cpu().numpy())\n",
    "        imagenames += imagename\n",
    "        probs += prob\n",
    "\n",
    "with open(os.path.join(opt.resultdir, 'submission_old.csv'), 'w', encoding='utf8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(['imagename', 'defect_prob'])\n",
    "    for info in zip(imagenames, probs):\n",
    "        imagename, prob = info\n",
    "        writer.writerow([imagename, str(prob[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee822391-2899-4cb7-92f1-db8cdf58f235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
