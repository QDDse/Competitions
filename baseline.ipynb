{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33be3e9-56b1-4b6d-8dd2-b3bc502b0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................\n",
      "...param: traindir: ../train/labeled_data/\n",
      "...param: train_metadir: ../\n",
      "...param: train_metafile: train_label.csv\n",
      "...param: testdir: ../test\n",
      "...param: test_metadir: None\n",
      "...param: test_metafile: None\n",
      "...param: epochs: 10\n",
      "...param: num_workers: 4\n",
      "...param: batch_size: 64\n",
      "...param: lr: 0.1\n",
      "...param: weight_decay: 1e-05\n",
      "...param: num_classes: 2\n",
      "...param: step_size: 5\n",
      "...param: gamma: 0.9\n",
      "...param: ckpt_name: None\n",
      "...param: submission_name: submission.csv\n",
      "...param: model_name: None\n",
      "...param: kfold: 5\n",
      "...param: device: cuda\n",
      "...param: resultdir: ./result\n",
      "...........................................................................\n"
     ]
    }
   ],
   "source": [
    "## Kflod-5\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from args import build_opt\n",
    "from loaders import build_loader, build_loader_new\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "opt = build_opt()\n",
    "\n",
    "from utils import create_logger\n",
    "import timm\n",
    "## logger\n",
    "logger = create_logger('../logging')\n",
    "##\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4465686-25f7-4634-a81f-d31a4b79895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重置opt\n",
    "opt.epochs = 5\n",
    "opt.lr = 1e-3\n",
    "opt.model_name = 'efficientnet_b6'\n",
    "opt.batch_size = 16\n",
    "opt.kfold = 5\n",
    "## random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba79efb-1cf1-4802-9b05-b6b652a76e74",
   "metadata": {},
   "source": [
    "## DEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604d04d7-08fa-4b5c-bdf4-1df5db11064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eca_swinnext26ts_256',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinnet26t_256',\n",
       " 'swinnet50ts_256']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = timm.list_models('*swin*')\n",
    "# model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "495e07e3-cecb-4696-8b5d-3ccde61e0976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25767\n",
       "6     1719\n",
       "2      533\n",
       "4      269\n",
       "7      255\n",
       "5      247\n",
       "3      223\n",
       "1      151\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../train_new.csv', index_col=0)\n",
    "train_df.head()\n",
    "train_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da63653-28b3-4b5e-a449-f42ae8f670c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../train_label.csv', 'r') as f:\n",
    "#     rows = f.readlines()\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77fa23-3900-4f7d-a094-5cf447eddfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = []\n",
    "# train_labels = []\n",
    "\n",
    "# for row in tqdm(rows, total= len(rows)):\n",
    "#     row = row.rstrip('\\n')\n",
    "#     print(row)\n",
    "#     train_img = row.split(',')[0]\n",
    "#     # print(train_img)\n",
    "#     train_lbl = row.split(',')[1]\n",
    "#     # print(train_lbl)\n",
    "#     train_imgs.append(train_img)\n",
    "#     train_labels.append(train_lbl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "161a2ed5-676f-4c40-b4c9-c6ba808a8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_multilbl = pd.DataFrame({'train_img': train_imgs, \n",
    "#                                  'label': train_labels\n",
    "#                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f9484e-4092-4f2f-bb82-54cfe2544f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25767\n",
       "6     1719\n",
       "2      533\n",
       "4      269\n",
       "7      255\n",
       "5      247\n",
       "3      223\n",
       "1      151\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts() # 8 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d0aba-0c98-4759-823e-c4bca3d09f9e",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44378487-57fb-4816-aa30-72f7ef5827d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqddse\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6547665b-3b1a-4328-a097-f77df843bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/autodl-tmp/HUWEI/baseline/wandb/run-20220904_212937-3kvcbs5s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering/runs/3kvcbs5s\" target=\"_blank\">Effi-b6-baseline_KFold4_with_aug_multilbl</a></strong> to <a href=\"https://wandb.ai/qddse/HUAWEI_lane_rendering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='HUAWEI_lane_rendering', \n",
    "    entity='qddse',\n",
    "    name='Effi-b6-baseline_KFold4_with_aug_multilbl',\n",
    "    reinit=True,\n",
    "    config=opt,\n",
    "    group='EffiNetb6',\n",
    "    job_type='train'\n",
    ")\n",
    "\n",
    "## update config\n",
    "# api = wandb.Api()\n",
    "# run = api.run('qddse/HUAWEI_lane_rendering/1us1v6o4')\n",
    "# run.config['model_name'] = opt.model_name\n",
    "# run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c5fa017-c690-4d96-a561-43d6a2165b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAIN Train\n",
    "# ckpt_middle = torch.load('../ckpts/8_22/efficientnet_b6_39_bestmodel.pth')\n",
    "# model.load_state_dict(ckpt_middle['model'])\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1048e6-eaef-4068-be2f-0c9c3fddd7c4",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccfa8dd9-e689-4e9f-9c5e-923a79c14d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Trainer\n",
    "class Trainer:\n",
    "    def __init__(self, dataloaders, optimizer, model, loss_fn, scheduler=None, device='cuda:0', amp=False, config=None):\n",
    "        self.train_loader, self.val_loader = dataloaders\n",
    "        self.train_loss = loss_fn\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.amp = amp\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        self.model.cuda()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = data_cache[0].cuda()\n",
    "            label = data_cache[1].long().cuda()\n",
    "            ## compute loss\n",
    "            pred = self.model(img)\n",
    "            loss = self.train_loss(pred, label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        return running_loss / (len(self.train_loader))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self):\n",
    "        self.model.eval()\n",
    "        valid_pbar = tqdm(enumerate(self.val_loader), total=len(self.val_loader))\n",
    "        valid_preds, valid_targets = [], []\n",
    "        valid_acc = 0.\n",
    "        for idx, cache in valid_pbar:\n",
    "            img = cache[0].cuda()\n",
    "            target = cache[1].cuda()\n",
    "            pred = self.model(img)\n",
    "            valid_acc += (pred.argmax(1) == target).sum().item()\n",
    "            \n",
    "        return valid_acc / len(self.val_loader.dataset)\n",
    "            \n",
    "    def train_one_epoch_with_mixup(self):\n",
    "        '''\n",
    "        Train one epoch using mixup\n",
    "        '''\n",
    "        if self.amp:\n",
    "            scaler = GradScaler()\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_labels = [], []\n",
    "        running_loss = 0\n",
    "        for bnum, data_cache in train_pbar:\n",
    "            img = self._convert_if_not_tensor(data_cache[0], dtype=torch.float32)\n",
    "            target = self._convert_if_not_tensor(data_cache[1], dtype=torch.float32)\n",
    "\n",
    "            bs = img.shape[0]\n",
    "            ## Support Amp with Mixup\n",
    "            if self.amp:\n",
    "                # Mixup\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(mix_img).squeeze()\n",
    "                        ## mixup loss\n",
    "                        loss_a = self.train_loss_fn(output, tar_a)\n",
    "                        loss_b = self.train_loss_fn(output, tar_b)\n",
    "                        loss = loss_a * lam + (1-lam) * loss_b\n",
    "                        \n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self. scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "                else:\n",
    "                    with autocast(enabled=True):\n",
    "                        output = self.model(img).squeeze()\n",
    "                        loss = self.train_loss_fn(output, target)\n",
    "                        loss = loss / self.config['N_ACCUM']\n",
    "                    scaler.scale(loss).backward()\n",
    "                    \n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                    \n",
    "            else:  # no amp\n",
    "                ## mixup allowed\n",
    "                if torch.randn(1)[0] < 0.5:\n",
    "                    mix_img, tar_a, tar_b, lam = mixup_augmentation(img, target, alpha=0.5)\n",
    "                    output = self.model(mix_img).squeeze()\n",
    "                    \n",
    "                    ## loss\n",
    "                    loss_a = self.train_loss_fn(output, tar_a)\n",
    "                    loss_b = self.train_loss_fn(output, tar_b)\n",
    "                    loss = loss_a * lam + (1-lam) * loss_b\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    if (bnum + 1)% self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "                else:\n",
    "                    output = self.model(img).squeeze()\n",
    "                    loss = self.train_loss_fn(output, target)\n",
    "                    loss = loss / self.config['N_ACCUM']\n",
    "                    loss.backward()\n",
    "\n",
    "                    if (bnum + 1) % self.config['N_ACCUM'] == 0:\n",
    "                        self.optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if self.scheduler:\n",
    "                            self.scheduler.step()\n",
    "                    running_loss += (loss.item() * bs)\n",
    "            train_pbar.set_description(desc=f'loss: {loss.item():.4f}')\n",
    "            running_loss /= len(self.train_loader)\n",
    "            \n",
    "            # Rescale the targets and output before chugging in a matrix\n",
    "            output = output.sigmoid().detach() * 100.0\n",
    "            target = target.detach() * 100.0\n",
    "            train_preds += [output.cpu().numpy()]\n",
    "            train_labels += [target.cpu().numpy()]\n",
    "        \n",
    "        all_train_preds = np.concatenate(train_preds)\n",
    "        all_train_labels = np.concatenate(train_labels)\n",
    "        \n",
    "        # Tidy\n",
    "        del output, target, train_preds, train_labels, loss, img, meta, all_train_preds, all_train_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return running_loss\n",
    "    \n",
    "    def fit(self, fold: int=None, epochs:int = 10, output_dir:str='./ckpts/826/04/', custom_name:str='model_best.pth', gain_train=None, is_wandb=True):\n",
    "        \"\"\"\n",
    "        Low-effort alternative for doing the complete training and validation process\n",
    "        args:\n",
    "            gain_train: str ,ckpts的地址\n",
    "        \"\"\"\n",
    "        ## scheduler\n",
    "        self.optimizer\n",
    "        best_loss = int(1e7)\n",
    "        best_acc = 0.0\n",
    "        if gain_train:\n",
    "            ckpt = torch.load(gain_train)\n",
    "            model_ckpt = ckpt['model']\n",
    "            self.model.load_state_dict(model_ckpt)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"{'*'*20} Epoch: {epoch} / {epochs} {'*'*20}\")\n",
    "            \n",
    "            train_running_loss = self.train_one_epoch()\n",
    "            print(f\"Training loss: {train_running_loss:.4f}\")\n",
    "            valid_acc = self.valid_one_epoch()\n",
    "            print(f\"Validation Acc : {valid_acc:.4f}\")\n",
    "            \n",
    "            if train_running_loss < best_loss:\n",
    "                best_loss = train_running_loss\n",
    "                self.save_model(output_dir, custom_name, loss_final=best_loss)\n",
    "                self.save_model(output_dir + '/fold_'+str(fold) + '/', 'model_' + str(epoch) + '.pth', best_loss)\n",
    "\n",
    "                print(f\"Saved model with train_loss: {best_loss:.4f}\")\n",
    "                es = 0\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter: {} / {}\".format(es, self.config['patience']))\n",
    "                if es > self.config['patience']:\n",
    "                    print('Early Stop with train_loss: {}, val_acc:{}'.format(train_running_loss, valid_acc))\n",
    "                    break\n",
    "            if best_acc < valid_acc:\n",
    "                best_acc = valid_acc\n",
    "                self.save_model(output_dir + 'via_acc', custom_name)\n",
    "        \n",
    "            ## logger\n",
    "            if is_wandb:\n",
    "                run.log({'epoch:': epoch, 'Fold': fold, 'loss_train:': train_running_loss, 'val_acc': valid_acc})\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "                \n",
    "    def save_model(self, path, name, verbose=False, loss_final=None):\n",
    "        \"\"\"\n",
    "        Saves the model at the provided destination\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "        except:\n",
    "            print(\"Errors encountered while making the output directory\")\n",
    "        torch.save({\n",
    "            'model':self.model.state_dict(), \n",
    "            'loss': loss_final,\n",
    "            },\n",
    "            os.path.join(path, name)\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"Model Saved at: {os.path.join(path, name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be7686d-02a7-4b82-9619-57b15c4f62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>train_15505.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642</th>\n",
       "      <td>train_09642.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23208</th>\n",
       "      <td>train_23208.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>train_07917.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23946</th>\n",
       "      <td>train_23946.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>train_13744.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>train_06531.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16565</th>\n",
       "      <td>train_16565.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23404</th>\n",
       "      <td>train_23404.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>train_00250.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>train_20476.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>train_11160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>train_24423.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>train_08615.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>train_12740.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>train_08340.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>train_04168.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>train_14734.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>train_17279.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>train_24978.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image  label  label_01\n",
       "15505  train_15505.png      0         0\n",
       "9642   train_09642.png      0         0\n",
       "23208  train_23208.png      0         0\n",
       "7917   train_07917.png      0         0\n",
       "23946  train_23946.png      0         0\n",
       "13744  train_13744.png      0         0\n",
       "6531   train_06531.png      0         0\n",
       "16565  train_16565.png      0         0\n",
       "23404  train_23404.png      0         0\n",
       "250    train_00250.png      0         0\n",
       "20476  train_20476.png      0         0\n",
       "11160  train_11160.png      0         0\n",
       "24423  train_24423.png      0         0\n",
       "8615   train_08615.png      0         0\n",
       "12740  train_12740.png      0         0\n",
       "8340   train_08340.png      0         0\n",
       "4168   train_04168.png      0         0\n",
       "14734  train_14734.png      0         0\n",
       "17279  train_17279.png      6         1\n",
       "24978  train_24978.png      0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 转化为二分类\n",
    "# def Convert_01(label):\n",
    "#     '''\n",
    "#     args:\n",
    "#         label:int\n",
    "#     '''\n",
    "#     if label == 0:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "# ## 将label 转化为0-1\n",
    "# train_df['label_01'] = train_df['label'].apply(lambda x: Convert_01(x))\n",
    "# train_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f019ce-8124-40e9-a6a7-1f9dce83661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test Dataset\n",
    "# from loaders import Rane_Dataset\n",
    "# data_set = Rane_Dataset(imagedir='../train/labeled_data/', df=train_df, transform=None)\n",
    "\n",
    "# loader =build_loader_new(imagedir='../train/labeled_data/', batch_size=32, num_workers=4, metafile=train_df)\n",
    "\n",
    "# inp = next(iter(loader))\n",
    "# inp[0].shape, inp[1]\n",
    "\n",
    "# # inp = data_set[0][0].unsqueeze(0)\n",
    "\n",
    "# from models import Effnet\n",
    "\n",
    "# # model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "# model = Effnet(model_name=opt.model_name).cuda()\n",
    "\n",
    "# out = model(inp[0].cuda())\n",
    "\n",
    "# target = inp[1]\n",
    "# target = target.long()\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# loss = criterion(out, target.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e64ae8b8-57a5-492b-8e1e-5123f5055e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist for this model. Using random initialization.\n"
     ]
    }
   ],
   "source": [
    "## train\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## modified model    \n",
    "from models import Effnet\n",
    "\n",
    "# model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "model = Effnet(model_name=opt.model_name)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# transform = T.Compose([\n",
    "#                       T.Resize((224, 224)),\n",
    "#                       #T.HorizontalFlip(p=0.5),\n",
    "#                       T.RandomHorizontalFlip(0.5),\n",
    "#                       T.RandomVerticalFlip(0.5),\n",
    "#                       # A.VerticalFlip(p=0.5),\n",
    "#                       # T.Random,\n",
    "#                       # A.RandomContrast(p=0.5),\n",
    "#                       T.RandomGrayscale(0.5),\n",
    "#                       # A.RandomBrightness(p=0.5),\n",
    "#                       T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#                       T.ToTensor(),\n",
    "#                 ])\n",
    "transform = A.Compose([\n",
    "                      A.Resize(300, 300),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                      A.RandomContrast(p=0.5),\n",
    "                      A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "transform_val = A.Compose([\n",
    "                      A.Resize(300, 300),\n",
    "                      # A.HorizontalFlip(p=0.5),\n",
    "                      # A.VerticalFlip(p=0.5),\n",
    "                      # A.RandomContrast(p=0.5),\n",
    "                      # A.RandomBrightness(p=0.5),\n",
    "                      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                      ToTensorV2(),\n",
    "                ])\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= 20, eta_min=1e-4)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "    \n",
    "# writer = SummaryWriter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b9fb3af-376e-4802-93fd-7626694050f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Fold: 0 / 5 ********************\n",
      "******************** Fold: 1 / 5 ********************\n",
      "******************** Fold: 2 / 5 ********************\n",
      "23331 5833\n",
      "******************** Epoch: 0 / 5 ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@810.109] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00016.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.109] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00000.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.109] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00032.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.112] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00064.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.112] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00096.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.116] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00080.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.132] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00048.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@810.136] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00112.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec50e16de054ee9a3b65956bb2dab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@810.154] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../train/labeled_data/train_00128.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/autodl-tmp/HUWEI/baseline/loaders.py\", line 38, in __getitem__\n    img = img.astype(np.float32)\nAttributeError: 'NoneType' object has no attribute 'astype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_267/2996941709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m     \u001b[0mTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../ckpts/9_04/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_267/3991746427.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, fold, epochs, output_dir, custom_name, gain_train, is_wandb)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'*'*20} Epoch: {epoch} / {epochs} {'*'*20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_running_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_267/3991746427.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cache\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_pbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/autodl-tmp/HUWEI/baseline/loaders.py\", line 38, in __getitem__\n    img = img.astype(np.float32)\nAttributeError: 'NoneType' object has no attribute 'astype'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bcac1a78e046d18fccf7dbe29da1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, split in enumerate(kf.split(train_df)):\n",
    "    print(f\"{'*'*20} Fold: {fold} / {opt.kfold} {'*'*20}\")\n",
    "    if fold == 0 or fold == 1:\n",
    "        continue\n",
    "    train_ = train_df.iloc[split[0]]\n",
    "    val_ = train_df.iloc[split[1]]\n",
    "    print(train_.shape[0], val_.shape[0])\n",
    "    \n",
    "    train_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=train_,\n",
    "        require_label=True,\n",
    "        transform = transform\n",
    "    )\n",
    "    val_loader = build_loader_new(\n",
    "        imagedir=opt.traindir,\n",
    "        batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers,\n",
    "        # metadir=opt.train_metadir,\n",
    "        metafile=val_,\n",
    "        require_label=True,\n",
    "        transform=transform_val\n",
    "    )\n",
    "    Train = Trainer((train_loader, val_loader), optimizer, model, loss_fn, scheduler=lr_scheduler)\n",
    "    Train.fit(fold=fold, epochs=opt.epochs, output_dir='../ckpts/9_04/', gain_train=None)\n",
    "    del Train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086c6e6-c2fd-44a2-8cca-67dc3f342c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('shutdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054fe5d-dd3d-4e93-938b-b1d6394d28b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Origin_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "577fd353-0d5f-46e9-a865-a54856eb9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...start training\n",
      "------ Epoch: 0 ------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_267/182170416.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepoch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "print('...start training')\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    print('------ Epoch: {} ------'.format(epoch))\n",
    "    \n",
    "    start_t = time.time()\n",
    "    min_loss = 100\n",
    "    epoch_l = 0\n",
    "    epoch_t = 0\n",
    "    for batch_idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        image, label = batch\n",
    "        image, label = image.to(opt.device), label.to(opt.device)\n",
    "        output = model(image)\n",
    "\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_l = l.item()\n",
    "        epoch_l += batch_l\n",
    "        batch_t = time.time() - start_t\n",
    "        epoch_t += batch_t\n",
    "        start_t = time.time()\n",
    "    lr_scheduler.step()\n",
    "    epoch_t = epoch_t / len(train_loader)\n",
    "    epoch_l = epoch_l / len(train_loader)\n",
    "    print('...epoch: {:3d}/{:3d}, loss: {:.4f}, average time: {:.2f}.'.format(\n",
    "        epoch + 1, opt.epochs, epoch_l, epoch_t))\n",
    "    ## WandB logging\n",
    "    run.log({'epoch:': epoch, 'loss_train:': epoch_l})\n",
    "    run.log({'epoch:': epoch, 'time_train:': epoch_t})\n",
    "    ## save model\n",
    "    if epoch_l < min_loss:\n",
    "        save_name = opt.model_name + '_' + str(epoch+20) + '_bestmodel.pth'\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'lr': opt.lr,\n",
    "            'loss': epoch_l},\n",
    "            os.path.join('../ckpts/8_25', save_name)\n",
    "        )\n",
    "        min_lossoss = epoch_l\n",
    "        ## Early-stop\n",
    "        es = 0\n",
    "    else:\n",
    "        es += 1\n",
    "        print('Counter {}/{}'.format(es, 4))  # 设置patience为4\n",
    "        if es > 3:\n",
    "            print('Early_stop with best model‘s running_loss:{}'.format(epoch_l))\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00130452-0157-44a8-b913-66e4398d9441",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SAVE CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af019f-f873-48bd-a81b-444fa93ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'model': model.state_dict(),\n",
    "#     'lr': '0.1*10 + 1e-4*10',\n",
    "#     'epoch': '10+10',},\n",
    "#     '../ckpts/res50_epoch10+10'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e65765-e296-4004-bd33-86dac55945b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"shutdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f9bf3-6d38-4583-8cf3-88a42b07dc71",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1f9f9e-d7ca-4bba-99bf-dba4a07b9113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...start predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee140a82dc747b5be5723f4b9fed5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## test_loader\n",
    "test_loader = build_loader(\n",
    "    imagedir=opt.testdir,\n",
    "    batch_size=opt.batch_size,\n",
    "    num_workers=opt.num_workers,\n",
    "    metadir=opt.test_metadir,\n",
    "    metafile=opt.test_metafile,\n",
    "    require_label=False\n",
    ")\n",
    "\n",
    "## 加载模型\n",
    "model = torchvision.models.resnet50(pretrained=False, num_classes=opt.num_classes).to(opt.device)\n",
    "ckpt = torch.load('../ckpts/baseline_724.pth')['model']\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "print('...start predicting')\n",
    "\n",
    "model.eval()\n",
    "to_prob = nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    imagenames, probs = list(), list()\n",
    "    for batch_idx, batch in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        image, imagename = batch\n",
    "        image = image.to(opt.device)\n",
    "        pred = model(image)\n",
    "        prob = to_prob(pred)\n",
    "        prob = list(prob.data.cpu().numpy())\n",
    "        imagenames += imagename\n",
    "        probs += prob\n",
    "\n",
    "with open(os.path.join(opt.resultdir, 'submission_old.csv'), 'w', encoding='utf8') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(['imagename', 'defect_prob'])\n",
    "    for info in zip(imagenames, probs):\n",
    "        imagename, prob = info\n",
    "        writer.writerow([imagename, str(prob[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee822391-2899-4cb7-92f1-db8cdf58f235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
